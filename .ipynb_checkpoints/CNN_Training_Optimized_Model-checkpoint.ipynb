{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recognition - Nerual Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import activations\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread # Need 'Imageio' 'Pillow' packages\n",
    "import cv2\n",
    "\n",
    "from math import floor, ceil\n",
    "import os\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from German traffic sign database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder_path = \"./German traffic sign dataset\" + \"/GTSRB_Training\" + \"/\"\n",
    "\n",
    "csv_content = [] # One numpy array per folder\n",
    "                 # Each numpy array x: image y: proprierties\n",
    "\n",
    "# Iterate over all subfolders to read the CSV file of each class\n",
    "for i in range(43):\n",
    "    train_dataset_path = main_folder_path + \"{:05.0f}\".format(i) + \"/\"\n",
    "    f_name = train_dataset_path + \"GT-\" + \"{:05.0f}\".format(i) + \".csv\"\n",
    "    csv_content.append(np.genfromtxt(f_name, delimiter=';', skip_header=1, dtype=str))\n",
    "print(csv_content[0][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images and respective class\n",
    "\n",
    "image = []\n",
    "img_num = 0\n",
    "labels = np.empty(0)\n",
    "\n",
    "for i in range(43):\n",
    "    image_class = []\n",
    "    train_dataset_path = main_folder_path + \"{:05.0f}\".format(i) + '/'\n",
    "    for label_name in enumerate(csv_content[i][:,0]):\n",
    "        image_class.append(imread(train_dataset_path + label_name[1])[:,:,0]) # Adding image\n",
    "        labels = np.append(labels, i) # Appending image class based on folder\n",
    "        img_num += 1\n",
    "    image.append(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image in every class\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = gridspec.GridSpec(nrows=7, ncols=7)\n",
    "\n",
    "for i in enumerate(image):\n",
    "    ax0 = fig.add_subplot(gs[i[0]//7, i[0]%7])\n",
    "    ax0.imshow(i[1][0])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of class population\n",
    "plt.hist(labels, len(image))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training set\n",
    "x_size = 32\n",
    "y_size = 32\n",
    "img_train = np.empty((img_num, x_size, y_size))\n",
    "\n",
    "elaborated = 0\n",
    "\n",
    "for image_set in enumerate(image):\n",
    "    for image_array in enumerate(image_set[1]):\n",
    "        # Cutting the image to match the content\n",
    "        x2 = int(csv_content[image_set[0]][image_array[0], 5]) \n",
    "        x1 = int(csv_content[image_set[0]][image_array[0], 3])\n",
    "        y2 = int(csv_content[image_set[0]][image_array[0], 6]) \n",
    "        y1 = int(csv_content[image_set[0]][image_array[0], 4])\n",
    "        size = max(x2-x1, y2-y1)\n",
    "        # Padding to have square images\n",
    "        padded = np.pad(np.asarray(image_array[1][x1:x2, y1:y2]), \\\n",
    "                        ((floor((size-x2+x1)/2), ceil((size-x2+x1)/2)),\\\n",
    "                         (floor((size-y2+y1)/2), ceil((size-y2+y1)/2))))\n",
    "        # Reshaping the image to match the selected dimension\n",
    "        reshaped = cv2.resize(padded, (x_size, y_size), interpolation = cv2.INTER_AREA)\n",
    "        # Copying the image inside the output array\n",
    "        np.copyto(img_train[elaborated,:,:], reshaped)\n",
    "        # Showing result\n",
    "        #plt.imshow(img_train[elaborated,:,:])\n",
    "        #plt.show()\n",
    "        #Images should be one after another to train the model\n",
    "        elaborated += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the train data to have a correct fit input\n",
    "print(img_train.shape)\n",
    "img_train_rsh = np.reshape(img_train, (img_train.shape[0], img_train.shape[1], img_train.shape[2],1))\n",
    "print(img_train_rsh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation data from the train dataset\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(img_train_rsh, labels, test_size=0.25)\n",
    "print(x_train.shape[0], x_test.shape[0], y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ground truth for classification\n",
    "print(y_train.shape)\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = to_categorical(y_train, len(image))\n",
    "Y_test = to_categorical(y_test, len(image))\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = Sequential()\n",
    "model_s.add(Conv2D(10, (7,7), strides=(1,1)))\n",
    "model_s.add(Activation(activations.relu))\n",
    "model_s.add(Conv2D(50, (4,4), strides=(1,1)))\n",
    "model_s.add(Activation(activations.relu))\n",
    "model_s.add(Conv2D(50, (4,4), strides=(1,1)))\n",
    "model_s.add(Activation(activations.relu))\n",
    "model_s.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_s.add(Flatten())\n",
    "model_s.add(Dense(50))\n",
    "model_s.add(Activation(activations.relu))\n",
    "model_s.add(Dense(43))\n",
    "model_s.add(Activation(activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_s.fit(x_train, Y_train, batch_size=50, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model_s.predict(x_test)\n",
    "y_test = np.argmax(y_test_prob)\n",
    "\n",
    "test_loss, test_acc = model_s.evaluate(x_test, Y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.save(\"./Models/model_s.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data to be sent to MCU for validation from CV test set\n",
    "\n",
    "to_test = np.reshape(x_test[:,:,:], (-1,1024))\n",
    "\n",
    "with open(\"./Test_data/image_arranged_cv.csv\", \"w\") as f:\n",
    "    np.savetxt(f, to_test[1:10,:], delimiter=',')\n",
    "    \n",
    "with open(\"./Test_data/image_annotation_cv.csv\", \"w\") as f:\n",
    "    np.savetxt(f, Y_test[1:10,:], delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting test data to network input dimension from data dataset\n",
    "\n",
    "main_folder_path = \"./German traffic sign dataset\"\n",
    "test_dataset_path = main_folder_path + \"/GTSRB_Testing\" + \"/GT-final_test.csv\"\n",
    "\n",
    "test_csv = (np.genfromtxt(test_dataset_path, delimiter=';', skip_header=1, dtype=str))\n",
    "\n",
    "image_test = []\n",
    "\n",
    "for name_img in test_csv:\n",
    "    image_test.append(imread(\"./German traffic sign dataset\" + \"/GTSRB_Testing\" + \"/\" + name_img[0])[:,:,0])\n",
    "    \n",
    "plt.imshow(image_test[0])\n",
    "plt.show()     \n",
    "\n",
    "# Count total number of images:\n",
    "img_test_num = len(image_test)\n",
    "                                 \n",
    "# Reshape test set\n",
    "img_test = np.empty((img_num, x_size, y_size))\n",
    "\n",
    "# Handling the classes\n",
    "test_annotation = to_categorical(test_csv[:, 7], len(image))\n",
    "\n",
    "for image_set in enumerate(image_test):\n",
    "    # Cutting the image to match the content\n",
    "    x2 = int(test_csv[image_set[0], 5]) \n",
    "    x1 = int(test_csv[image_set[0], 3])\n",
    "    y2 = int(test_csv[image_set[0], 6]) \n",
    "    y1 = int(test_csv[image_set[0], 4])\n",
    "    size = max(x2-x1, y2-y1)\n",
    "    # Padding to have square images\n",
    "    padded = np.pad(np.asarray(image_set[1][x1:x2, y1:y2]), \\\n",
    "                    ((floor((size-x2+x1)/2), ceil((size-x2+x1)/2)),\\\n",
    "                     (floor((size-y2+y1)/2), ceil((size-y2+y1)/2))))\n",
    "    # Reshaping the image to match the selected dimension\n",
    "    reshaped = cv2.resize(padded, (x_size, y_size), interpolation = cv2.INTER_AREA)\n",
    "    # Copying the image inside the output array\n",
    "    np.copyto(img_test[image_set[0],:,:], reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = np.reshape(img_test[:,:,:], (-1,1024))\n",
    "\n",
    "with open(\"./Test_data/image_arranged.csv\", \"w\") as f:\n",
    "    np.savetxt(f, to_test[1:10,:], delimiter=',')\n",
    "    \n",
    "with open(\"./Test_data/image_annotation.csv\", \"w\") as f:\n",
    "    np.savetxt(f, test_annotation[1:10,:], delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
