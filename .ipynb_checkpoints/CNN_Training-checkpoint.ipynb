{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recognition - Nerual Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread # Need 'Imageio' 'Pillow' packages\n",
    "import cv2\n",
    "\n",
    "from math import floor, ceil\n",
    "import os\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from German traffic sign database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00000_00001.ppm' '30' '30' '5' '5' '25' '25' '0']\n"
     ]
    }
   ],
   "source": [
    "main_folder_path = \"./German traffic sign dataset\" + \"/GTSRB_Training\" + \"/\"\n",
    "\n",
    "csv_content = [] # One numpy array per folder\n",
    "                 # Each numpy array x: image y: proprierties\n",
    "\n",
    "# Iterate over all subfolders to read the CSV file of each class\n",
    "for i in range(43):\n",
    "    train_dataset_path = main_folder_path + \"{:05.0f}\".format(i) + \"/\"\n",
    "    f_name = train_dataset_path + \"GT-\" + \"{:05.0f}\".format(i) + \".csv\"\n",
    "    csv_content.append(np.genfromtxt(f_name, delimiter=';', skip_header=1, dtype=str))\n",
    "print(csv_content[0][1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e1d61892089c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_dataset_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_folder_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"{:05.0f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_content\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mimage_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Adding image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Appending image class based on folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mimg_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mformat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_read_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mmodename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMODENAMES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36msearch_read_format\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    687\u001b[0m         \u001b[1;31m# Select the first that can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_formats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36mcan_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mformat\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mread\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcan_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36m_can_read\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mfactory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPEN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugin_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstbytes\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36mfirstbytes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \"\"\"\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_firstbytes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_first_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_firstbytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_read_first_bytes\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# Prepare\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# A directory, e.g. for DICOM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\marco\\documents\\github\\embedded-neural-net-traffic-sign-recognition\\env\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uri_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mURI_ZIPPED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the images and respective class\n",
    "\n",
    "image = []\n",
    "img_num = 0\n",
    "labels = np.empty(0)\n",
    "\n",
    "for i in range(43):\n",
    "    image_class = []\n",
    "    train_dataset_path = main_folder_path + \"{:05.0f}\".format(i) + '/'\n",
    "    for label_name in enumerate(csv_content[i][:,0]):\n",
    "        image_class.append(imread(train_dataset_path + label_name[1])[:,:,0]) # Adding image\n",
    "        labels = np.append(labels, i) # Appending image class based on folder\n",
    "        img_num += 1\n",
    "    image.append(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first image in every class\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = gridspec.GridSpec(nrows=7, ncols=7)\n",
    "\n",
    "for i in enumerate(image):\n",
    "    ax0 = fig.add_subplot(gs[i[0]//7, i[0]%7])\n",
    "    ax0.imshow(i[1][0])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of class population\n",
    "plt.hist(labels, len(image))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapting the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training set\n",
    "x_size = 32\n",
    "y_size = 32\n",
    "img_train = np.empty((img_num, x_size, y_size))\n",
    "\n",
    "elaborated = 0\n",
    "\n",
    "for image_set in enumerate(image):\n",
    "    for image_array in enumerate(image_set[1]):\n",
    "        # Cutting the image to match the content\n",
    "        x2 = int(csv_content[image_set[0]][image_array[0], 5]) \n",
    "        x1 = int(csv_content[image_set[0]][image_array[0], 3])\n",
    "        y2 = int(csv_content[image_set[0]][image_array[0], 6]) \n",
    "        y1 = int(csv_content[image_set[0]][image_array[0], 4])\n",
    "        size = max(x2-x1, y2-y1)\n",
    "        # Padding to have square images\n",
    "        padded = np.pad(np.asarray(image_array[1][x1:x2, y1:y2]), \\\n",
    "                        ((floor((size-x2+x1)/2), ceil((size-x2+x1)/2)),\\\n",
    "                         (floor((size-y2+y1)/2), ceil((size-y2+y1)/2))))\n",
    "        # Reshaping the image to match the selected dimension\n",
    "        reshaped = cv2.resize(padded, (x_size, y_size), interpolation = cv2.INTER_AREA)\n",
    "        # Copying the image inside the output array\n",
    "        np.copyto(img_train[elaborated,:,:], reshaped)\n",
    "        # Showing result\n",
    "        #plt.imshow(img_train[elaborated,:,:])\n",
    "        #plt.show()\n",
    "        #Images should be one after another to train the model\n",
    "        elaborated += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the train data to have a correct fit input\n",
    "print(img_train.shape)\n",
    "img_train_rsh = np.reshape(img_train, (img_train.shape[0], img_train.shape[1], img_train.shape[2],1))\n",
    "print(img_train_rsh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and validation data from the train dataset\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(img_train_rsh, labels, test_size=0.25)\n",
    "print(x_train.shape[0], x_test.shape[0], y_train.shape[0], y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ground truth for classification\n",
    "print(y_train.shape)\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = to_categorical(y_train, len(image))\n",
    "Y_test = to_categorical(y_test, len(image))\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional network model - SOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(200, (7,7), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(200, (4,4), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(200, (4,4), strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, Y_train, batch_size=50, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model.predict(x_test)\n",
    "y_test = np.argmax(y_test_prob)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, Y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = Sequential()\n",
    "model_s.add(Conv2D(10, (4,4), strides=(1,1), activation='relu'))\n",
    "model_s.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_s.add(Flatten())\n",
    "model_s.add(Dense(50, activation='relu'))\n",
    "model_s.add(Dense(50, activation='relu'))\n",
    "model_s.add(Dense(43, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model_s.fit(x_train, Y_train, batch_size=50, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = model_s.predict(x_test)\n",
    "y_test = np.argmax(y_test_prob)\n",
    "\n",
    "test_loss, test_acc = model_s.evaluate(x_test, Y_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s.save(\"model_s.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data to be sent to MCU for validation from CV test set\n",
    "\n",
    "to_test = np.reshape(x_test[:,:,:], (-1,1024))\n",
    "\n",
    "with open(\"image_arranged_cv.csv\", \"w\") as f:\n",
    "    np.savetxt(f, to_test[1:10,:], delimiter=',')\n",
    "    \n",
    "with open(\"image_annotation_cv.csv\", \"w\") as f:\n",
    "    np.savetxt(f, Y_test[1:10,:], delimiter=',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting test data to network input dimension from data dataset\n",
    "\n",
    "main_folder_path = \"./German traffic sign dataset\"\n",
    "test_dataset_path = main_folder_path + \"/GTSRB_Testing\" + \"/GT-final_test.csv\"\n",
    "\n",
    "test_csv = (np.genfromtxt(test_dataset_path, delimiter=';', skip_header=1, dtype=str))\n",
    "\n",
    "image_test = []\n",
    "\n",
    "for name_img in test_csv:\n",
    "    image_test.append(imread(\"./German traffic sign dataset\" + \"/GTSRB_Testing\" + \"/\" + name_img[0])[:,:,0])\n",
    "    \n",
    "plt.imshow(image_test[0])\n",
    "plt.show()     \n",
    "\n",
    "# Count total number of images:\n",
    "img_test_num = len(image_test)\n",
    "                                 \n",
    "# Reshape test set\n",
    "img_test = np.empty((img_num, x_size, y_size))\n",
    "\n",
    "# Handling the classes\n",
    "img_annotation = to_categorical(test_csv[:, 7], len(image))\n",
    "\n",
    "for image_set in enumerate(image_test):\n",
    "    # Cutting the image to match the content\n",
    "    x2 = int(test_csv[image_set[0], 5]) \n",
    "    x1 = int(test_csv[image_set[0], 3])\n",
    "    y2 = int(test_csv[image_set[0], 6]) \n",
    "    y1 = int(test_csv[image_set[0], 4])\n",
    "    size = max(x2-x1, y2-y1)\n",
    "    # Padding to have square images\n",
    "    padded = np.pad(np.asarray(image_set[1][x1:x2, y1:y2]), \\\n",
    "                    ((floor((size-x2+x1)/2), ceil((size-x2+x1)/2)),\\\n",
    "                     (floor((size-y2+y1)/2), ceil((size-y2+y1)/2))))\n",
    "    # Reshaping the image to match the selected dimension\n",
    "    reshaped = cv2.resize(padded, (x_size, y_size), interpolation = cv2.INTER_AREA)\n",
    "    # Copying the image inside the output array\n",
    "    np.copyto(img_test[image_set[0],:,:], reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_test = np.reshape(img_test[:,:,:], (-1,1024))\n",
    "\n",
    "with open(\"image_arranged.csv\", \"w\") as f:\n",
    "    np.savetxt(f, to_test[1:10,:], delimiter=',')\n",
    "    \n",
    "with open(\"image_annotation.csv\", \"w\") as f:\n",
    "    np.savetxt(f, img_annotation[1:10,:], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
